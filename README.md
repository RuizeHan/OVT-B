# OVT-B
OVT-B: A New Large-Scale Benchmark for Open-Vocabulary Multi-Object Tracking


Open-vocabulary object perception has become an important topic in artificial1
intelligence, which aims to identify objects with novel classes that have not been
seen during training. Under this setting, open-vocabulary object detection (OVD) in3
a single image has been studied in much literature. However, the open-vocabulary4
object tracking (OVT) from a video is less studied, and a reason is the shortage
of benchmarks. In this work, we have built a new large-scale benchmark for
open-vocabulary multi-object tracking namely OVT-B. OVT-B contains 1,0487
categories of objects and 1,973 videos with 63,7608 bounding box annotations,8
which is much larger than the sole open-vocabulary tracking dataset, i.e., OV-TAO-9
val dataset (200+ categories, 900+ videos). The proposed OVT-B can be used as10
a new benchmark to pave the way for the research of OVT. We also develop a11
simple yet effective baseline method for OVT. It integrates the motion features for12
object tracking, which is an important feature for MOT but was ignored in the previous13
OVT methods. Experimental results have verified the usefulness of the proposed14
benchmark and the effectiveness of our method.
